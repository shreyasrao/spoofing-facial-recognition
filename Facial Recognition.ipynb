{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spoofing Facial Recognition - Shreyas Rao\n",
    "\n",
    "\n",
    "\n",
    "Facial recognition is gaining increasing traction as a means to authenticate. This makes it a prime target for spoofing attacks. In this notebook, we investigate whether having an enrollment image with a smile is more susceptible to spoofing than a neutral enrollment image. Based on that analysis, we will decide if users should be prevented from using a smiling reference image to authenticate themselves.\n",
    "\n",
    "Key terms:\n",
    "* Enrollment image: the image used as the known person in the recognition program\n",
    "* True positive (TP): image CORRECTLY identified as the enrollment image\n",
    "* False positive (FP): image INCORRECTLY identified as the enrollment image (SPOOF)\n",
    "* True negative (TN): image CORRECTLY identified as NOT the enrollment image\n",
    "* False negative (FN): image INCORRECTLY identified as NOT the enrollment image\n",
    "\n",
    "For facial recognition, we used this open source project:\n",
    "\n",
    "https://github.com/ageitgey/face_recognition/\n",
    "\n",
    "Once installed, we can run face_recognition from terminal:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$face_recognition <known_folder> <unknown_folder> --tolerance <0.00-1>\n",
    " uknownFile1;knowFileName # Indicates an identification\n",
    " .....\n",
    " unknownFileN;unknown_person # No identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output is a list of filenames located in the unknown folder, followed by the names of face it recognizes from the known folder. Since we are investigating spoofing with one shot face recognition, there is only one picture present in the known folder.\n",
    "\n",
    "## Data Preparation\n",
    "\n",
    "We will be using a series of publicly available face datasets. Each file is named using a subjectID, expression (smile, neutral, etc.) and an optional number. We reformat each file as follows to have a universal naming scheme across all datasets:\n",
    "\n",
    "(\"original\"|\"transformed\")-(subjectID)-(expression)-(imageID).jpg"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "original-s12-neutral-32.jpeg #Example file names\n",
    "original-HV-smile-11.jpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have reformatted the names, we grouped them in different folders as \"smile\" or \"neutral\"\n",
    "\n",
    "\n",
    "## Initial Analysis\n",
    "In order to confirm that smiling enrollment images were in fact more likely to be spoofed, we check if the number of false positives in smiling image subset is in fact greater than false positives in neutral subset\n",
    "\n",
    "### Batch Processing:\n",
    "For our initial tests, we will be using the FM dataset which is a series of manually aligned frontal images of subjects with smiling and neutral images:\n",
    "https://github.com/shreyasrao/public/tree/master/unifyIdProject/fmDataSetCombined/smile\n",
    "https://github.com/shreyasrao/public/tree/master/unifyIdProject/fmDataSetCombined/neutral\n",
    "\n",
    "To process the entire dataset, we have to first set up the batch test zone.\n",
    "https://github.com/shreyasrao/public/tree/master/unifyIdProject/fmDataSetCombined/batchTestZone/neutralBatchTest\n",
    "\n",
    "Directory structure:\n",
    "* all : all of the pictures belonging to this dataset and expression\n",
    "* known: leave empty. Script will populate this folder accordingly\n",
    "* empty & noFaceDetected: leave empty. Script uses these for error handling\n",
    "\n",
    "Since running the test against all the images for all tolerance levels takes a long time (1-2 hours on my machine), I decided to randomize the batch testing process. A script selects a subject id for each tolerance level randomly based on the images in the neutral folder. Then we run the batch test script using the randomly generated subject IDs.\n",
    "\n",
    "The randomized batch test script does the following:\n",
    "* Checks if it can find a face in all images in the \"all\" folder. This is done by running face_regonition in the \"all\" folder against the \"empty\" folder\n",
    "    * If no face is found, a warning is raised, and that file is moved to the noFaceDetected folder and excluding from our runs\n",
    "* For each tolerance value in range(0,100):\n",
    "    * Find the random subject ID corresponding to the tolerance level\n",
    "    * Select that image from \"all\" folder and copy to \"known\" folder with the name \"enrolled.jpg\". This is the enrollment step\n",
    "        * A run is performed against this enrolled image. We parse the output and calculate TP, FP, TN, FN counts\n",
    "        * A global count is update after each new enrollment image using the tolerance value from earlier\n",
    "    * The count totals are printed to console and cleared for the next run which will use a new tolerance value"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Randomized Batch Test scipt\n",
    "import os, sys, re, random\n",
    "import subprocess\n",
    "from shutil import copyfile\n",
    "\n",
    "inFile = sys.argv[1]\n",
    "\n",
    "file = open(inFile,\"r\")\n",
    "rand = file.readlines()\n",
    "\n",
    "def getSubject(fileName):\n",
    "        return fileName.split(\"-\")[1]\n",
    "\n",
    "def analyzeRun(enrolledImg, res):\n",
    "\ttrueSubject = getSubject(enrolledImg)\n",
    "\n",
    "\trunStats = {'enrolled': enrolledImg, 'fP': 0, 'tP': 0, 'fN': 0, 'tN':0}\n",
    "\n",
    "\tfor r in res.splitlines():\n",
    "\t\tif \"unknown\" in r:\n",
    "\t\t\t#print(r)\n",
    "\t\t\t#this image was not detected\n",
    "\t\t\t\n",
    "\t\t\ttestSubject = getSubject(r)\n",
    "\t\t\tif testSubject==trueSubject:\n",
    "\t\t\t\trunStats['fN'] = runStats['fN']+1\n",
    "\t\t\telse:\n",
    "\t\t\t\trunStats['tN'] = runStats['tN']+1\n",
    "\n",
    "\t\tif \"enrolled\" in r:\n",
    "\t\t\ttestSubject = getSubject(r)\n",
    "\t\t\tif testSubject==trueSubject:\n",
    "\t\t\t\trunStats['tP'] = runStats['tP']+1\n",
    "\t\t\telse:\n",
    "\t\t\t\trunStats['fP'] = runStats['fP']+1\n",
    "\t\t\t\t#print(\"Found: \" + trueSubject + \" in \"+ r.split(\",\")[0] +  \". Actual subject was: \" + testSubject + \". Tuple|\" + trueSubject +\"|\" + testSubject  )\n",
    "\t\n",
    "\t#print(runStats)\n",
    "\treturn runStats\n",
    "\n",
    "\n",
    "\n",
    "def runDetection(enrolledImg,t):\n",
    "\ttString = \"-- \" + str(t)\n",
    "\tprint(\"RUNNING AGAINST: \" + enrolledImg + tString)\n",
    "\t#print(tString)\n",
    "\tproc = subprocess.Popen(['face_recognition', 'known/',  'all/', '--tolerance', str(t)], stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "\n",
    "\tres = proc.communicate()[0].decode(\"utf-8\")\n",
    "\treturn analyzeRun(enrolledImg,res)\n",
    "\n",
    "def updateGlobalStats(g,r):\n",
    "\tg['tP'] = g['tP'] + r['tP']\n",
    "\tg['tN'] = g['tN'] + r['tN']\n",
    "\tg['fP'] = g['fP'] + r['fP']\n",
    "\tg['fN'] = g['fN'] + r['fN']\n",
    "\n",
    "\n",
    "# Begin my running all against empty. Look for WARNING\n",
    "# Split lines, identify the file name and move the image to noID folder\n",
    "proc = subprocess.Popen(['face_recognition', 'all/',  'empty/'], stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "res = proc.communicate()[0].decode(\"utf-8\")\n",
    "for line in res.splitlines():\n",
    "\tif \"WARNING\" in line:\n",
    "\t\tmsg = line.split(\" \")\n",
    "\t\tnoIdFile = msg[-3][:-1]\n",
    "\t\tprint(\"Moving: \" + noIdFile)\n",
    "\t\tos.rename(noIdFile,\"noFaceDetected/\"+noIdFile)\n",
    "\n",
    "globalStats = {'fP': 0, 'tP': 0, 'fN': 0, 'tN':0}\n",
    "\n",
    "\n",
    "def clearStats(d):\n",
    "\tfor key in d:\n",
    "\t\td[key] = 0\n",
    "\n",
    "# This is the entry to the script\n",
    "for tol in range(0,100):\n",
    "\tt = tol/100\n",
    "\tt = str(t)\n",
    "\tf = rand[tol].rstrip()\n",
    "\tfor _root,_dirs,files in os.walk(\"all/\"):\n",
    "\t\tfor file in files:\n",
    "\t\t\tif \"jp\" in file:\n",
    "\t\t\t\ts= file.split(\"-\")\n",
    "\t\t\t\tif f == s[1]:\n",
    "\t\t\t\t\tf = \"-\".join(s)\n",
    "\t\t\t\t\tbreak\n",
    "\tprint(f)\t\n",
    "\tenrolledImg = f \n",
    "\tcopyfile(os.path.join(\"all/\",f),\"known/enrolled.jpg\")\n",
    "\trunRes = runDetection(f,t)\n",
    "\tupdateGlobalStats(globalStats,runRes)\n",
    "\tprint(\"Tol: \" + t + \" | \" + str(globalStats))\n",
    "\tclearStats(globalStats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script outputs all the counts onto terminal. Pipe the output to a txt file and pass it to grabData.py:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$python grabData.py results.txt\n",
    ">[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 3, 4, 2, 5, 3, 2, 24, 16, 16, 8, 19, 18, 18, 33, 33, 65, 99, 44, 107, 96, 108, 140, 121, 154, 155, 120, 182, 188, 125, 168, 185, 192, 166, 198, 193, 196, 199, 196, 199, 198, 199]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily modify grabData to capture any metric of our interest but currently it's only grabbing the FP counts. Repeat the same steps for the smile images and copy the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "662\n",
      "724\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "n = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 3, 1, 0, 1, 6, 18, 16, 11, 22, 20, 28, 29, 13, 79, 92, 43, 84, 105, 83, 100, 125, 139, 148, 88, 175, 156, 138, 182, 176, 189, 149, 195, 194, 194, 197, 195, 199, 198, 198]\n",
    "neutralFPSum = np.sum(n[50:80])\n",
    "print(neutralFPSum)\n",
    "s = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 3, 4, 2, 5, 3, 2, 24, 16, 16, 8, 19, 18, 18, 33, 33, 65, 99, 44, 107, 96, 108, 140, 121, 154, 155, 120, 182, 188, 125, 168, 185, 192, 166, 198, 193, 196, 199, 196, 199, 198, 199]\n",
    "smileFPSum = np.sum(s[50:80])\n",
    "print(smileFPSum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that in a tolerance range of 0.55-0.8, smile images are in fact getting more false positives. Although this isn't an issue at lower tolerances (since the recognition is very robust), we will investigate whether we can reduce that difference by somehow transforming the enrollment image. This way, a user could select any enrollment image of their choice.\n",
    "\n",
    "## Initial Attempts\n",
    "\n",
    "### Perspective Filter\n",
    "Our first idea was to remove the smile from the enrollment image. All material referenced opencv and dlib modules. After struggling with it quite some time, we were only able to install dlib but not openCV on mac OS. Since these two modules are in heavy use in the image modification space, we had to use a different approach. We then attempted to manually transform the image using a perspective filter. The motivation for this came from the observation that the spoof outlined in the paper had Vinay and John take smile enrollment pictures at an angled pose. We attempted to correct this, in the hopes that the transformed smile image would have a much different encoding than the other smile images. Using some online material we implemented a perspective filter using PIL:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy\n",
    "import sys\n",
    "from PIL import Image\n",
    "\n",
    "def find_coeffs(pa, pb):\n",
    "    matrix = []\n",
    "    for p1, p2 in zip(pa, pb):\n",
    "        matrix.append([p1[0], p1[1], 1, 0, 0, 0, -p2[0]*p1[0], -p2[0]*p1[1]])\n",
    "        matrix.append([0, 0, 0, p1[0], p1[1], 1, -p2[1]*p1[0], -p2[1]*p1[1]])\n",
    "\n",
    "    A = numpy.matrix(matrix, dtype=numpy.float)\n",
    "    B = numpy.array(pb).reshape(8)\n",
    "\n",
    "    res = numpy.dot(numpy.linalg.inv(A.T * A) * A.T, B)\n",
    "    return numpy.array(res).reshape(8)\n",
    "\n",
    "img = Image.open(sys.argv[1])\n",
    "width, height = img.size\n",
    "\n",
    "coeffs = find_coeffs(\n",
    "        [(0, 0), (256, 0), (256, 256), (0, 256)],\n",
    "        [(0, 0), (256, 0), (336, 256), (-80, 256)])\n",
    "\n",
    "img.transform((width, height), Image.PERSPECTIVE, coeffs,\n",
    "        Image.BICUBIC).save(sys.argv[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From test runs, it became obvious that the approach did not help. In fact it generated orders of magnitude more \n",
    "false positives than the smiling enrollment image.\n",
    "\n",
    "### Modifying the API\n",
    "Then we turned to the face_recognition program which was at the heart of the analysis. Instead of altering the image to alter the encoding, we wanted to see if we could alter the API. We found the command 'face_recognition' is a wrapper for cli.py:\n",
    "\n",
    "https://github.com/ageitgey/face_recognition/blob/master/face_recognition/cli.py\n",
    "\n",
    "Cli.py internally makes calls to api.py:\n",
    "\n",
    "https://github.com/ageitgey/face_recognition/blob/master/face_recognition/api.py\n",
    "\n",
    "So api.py was the backend logic for the image detection module. Specifically, 'compare_faces' calls 'face_encodings' which returns a 128D vector based on the face landmarks identified. If the distance between the known encoding and the unknown encoding is less than the tolerance parameter, a match is found.\n",
    "\n",
    "We attempted modify the encoding for images such that landmarks related to a smiling face ('top lip', 'bottom lip') would be randomized from a set of neutral lip/mouth landmarks. This would increase the distance between true positives, and hopefully past the threshold for a match. Modifying landmarks required tinkering with a dlib full_object_detection object that is returned from raw_landmarks.\n",
    "\n",
    "http://dlib.net/python/index.html\n",
    "\n",
    "Soon it became clear that we couldn't modify mouth landmarks in full_object_detection object. We decided to construct a new object with our modified landmark data. full_object_detection was created after a call to shape_predictor. Tinkering with the shape predictor model would make intensive changes to the face recognition program, so we decided to try a different approach.\n",
    "\n",
    "## A Ray of Hope\n",
    "\n",
    "Running out of ideas and time, we decided to go all in on image transformation. We still were not able to get openCV running on mac, so we installed Ubuntu. We were able to install openCV relatively easily. The euphoria didn't last long, as we soon discovered that dlib would not compile. After trying various \"solutions\" with no luck, our backs were against the wall. In one last move of desperation, we checked online for a VM with openCV and dlib installed ... and Viola!!! A gift from the gods:\n",
    "\n",
    "https://medium.com/@ageitgey/try-deep-learning-in-python-now-with-a-fully-pre-configured-vm-1d97d4c3e9b\n",
    "\n",
    "Now that everything was up and running, we wanted to check if there were any tools for blending faces. We came across this amazing tool by Matthew Earl:\n",
    "\n",
    "https://matthewearl.github.io/2015/07/28/switching-eds-with-python/\n",
    "https://github.com/matthewearl/faceswap/blob/master/faceswap.py"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "# Copyright (c) 2015 Matthew Earl\n",
    "# \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "# \n",
    "#     The above copyright notice and this permission notice shall be included\n",
    "#     in all copies or substantial portions of the Software.\n",
    "# \n",
    "#     THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n",
    "#     OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n",
    "#     MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n",
    "#     NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n",
    "#     DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n",
    "#     OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n",
    "#     USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "\n",
    "\"\"\"\n",
    "This is the code behind the Switching Eds blog post:\n",
    "    http://matthewearl.github.io/2015/07/28/switching-eds-with-python/\n",
    "See the above for an explanation of the code below.\n",
    "To run the script you'll need to install dlib (http://dlib.net) including its\n",
    "Python bindings, and OpenCV. You'll also need to obtain the trained model from\n",
    "sourceforge:\n",
    "    http://sourceforge.net/projects/dclib/files/dlib/v18.10/shape_predictor_68_face_landmarks.dat.bz2\n",
    "Unzip with `bunzip2` and change `PREDICTOR_PATH` to refer to this file. The\n",
    "script is run like so:\n",
    "    ./faceswap.py <head image> <face image>\n",
    "If successful, a file `output.jpg` will be produced with the facial features\n",
    "from `<head image>` replaced with the facial features from `<face image>`.\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy\n",
    "\n",
    "import sys\n",
    "\n",
    "PREDICTOR_PATH = \"/home/matt/dlib-18.16/shape_predictor_68_face_landmarks.dat\"\n",
    "SCALE_FACTOR = 1 \n",
    "FEATHER_AMOUNT = 11\n",
    "\n",
    "FACE_POINTS = list(range(17, 68))\n",
    "MOUTH_POINTS = list(range(48, 61))\n",
    "RIGHT_BROW_POINTS = list(range(17, 22))\n",
    "LEFT_BROW_POINTS = list(range(22, 27))\n",
    "RIGHT_EYE_POINTS = list(range(36, 42))\n",
    "LEFT_EYE_POINTS = list(range(42, 48))\n",
    "NOSE_POINTS = list(range(27, 35))\n",
    "JAW_POINTS = list(range(0, 17))\n",
    "\n",
    "# Points used to line up the images.\n",
    "ALIGN_POINTS = (LEFT_BROW_POINTS + RIGHT_EYE_POINTS + LEFT_EYE_POINTS +\n",
    "                               RIGHT_BROW_POINTS + NOSE_POINTS + MOUTH_POINTS)\n",
    "\n",
    "# Points from the second image to overlay on the first. The convex hull of each\n",
    "# element will be overlaid.\n",
    "#OVERLAY_POINTS = [\n",
    "#    LEFT_EYE_POINTS + RIGHT_EYE_POINTS + LEFT_BROW_POINTS + RIGHT_BROW_POINTS,\n",
    "#    NOSE_POINTS + MOUTH_POINTS,\n",
    "#]\n",
    "\n",
    "OVERLAY_POINT = [MOUTH_POINTS]\n",
    "\n",
    "# Amount of blur to use during colour correction, as a fraction of the\n",
    "# pupillary distance.\n",
    "COLOUR_CORRECT_BLUR_FRAC = 0.6\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(PREDICTOR_PATH)\n",
    "\n",
    "class TooManyFaces(Exception):\n",
    "    pass\n",
    "\n",
    "class NoFaces(Exception):\n",
    "    pass\n",
    "\n",
    "def get_landmarks(im):\n",
    "    rects = detector(im, 1)\n",
    "    \n",
    "    if len(rects) > 1:\n",
    "        raise TooManyFaces\n",
    "    if len(rects) == 0:\n",
    "        raise NoFaces\n",
    "\n",
    "    return numpy.matrix([[p.x, p.y] for p in predictor(im, rects[0]).parts()])\n",
    "\n",
    "def annotate_landmarks(im, landmarks):\n",
    "    im = im.copy()\n",
    "    for idx, point in enumerate(landmarks):\n",
    "        pos = (point[0, 0], point[0, 1])\n",
    "        cv2.putText(im, str(idx), pos,\n",
    "                    fontFace=cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,\n",
    "                    fontScale=0.4,\n",
    "                    color=(0, 0, 255))\n",
    "        cv2.circle(im, pos, 3, color=(0, 255, 255))\n",
    "    return im\n",
    "\n",
    "def draw_convex_hull(im, points, color):\n",
    "    points = cv2.convexHull(points)\n",
    "    cv2.fillConvexPoly(im, points, color=color)\n",
    "\n",
    "def get_face_mask(im, landmarks):\n",
    "    im = numpy.zeros(im.shape[:2], dtype=numpy.float64)\n",
    "\n",
    "    for group in OVERLAY_POINTS:\n",
    "        draw_convex_hull(im,\n",
    "                         landmarks[group],\n",
    "                         color=1)\n",
    "\n",
    "    im = numpy.array([im, im, im]).transpose((1, 2, 0))\n",
    "\n",
    "    im = (cv2.GaussianBlur(im, (FEATHER_AMOUNT, FEATHER_AMOUNT), 0) > 0) * 1.0\n",
    "    im = cv2.GaussianBlur(im, (FEATHER_AMOUNT, FEATHER_AMOUNT), 0)\n",
    "\n",
    "    return im\n",
    "    \n",
    "def transformation_from_points(points1, points2):\n",
    "    \"\"\"\n",
    "    Return an affine transformation [s * R | T] such that:\n",
    "        sum ||s*R*p1,i + T - p2,i||^2\n",
    "    is minimized.\n",
    "    \"\"\"\n",
    "    # Solve the procrustes problem by subtracting centroids, scaling by the\n",
    "    # standard deviation, and then using the SVD to calculate the rotation. See\n",
    "    # the following for more details:\n",
    "    #   https://en.wikipedia.org/wiki/Orthogonal_Procrustes_problem\n",
    "\n",
    "    points1 = points1.astype(numpy.float64)\n",
    "    points2 = points2.astype(numpy.float64)\n",
    "\n",
    "    c1 = numpy.mean(points1, axis=0)\n",
    "    c2 = numpy.mean(points2, axis=0)\n",
    "    points1 -= c1\n",
    "    points2 -= c2\n",
    "\n",
    "    s1 = numpy.std(points1)\n",
    "    s2 = numpy.std(points2)\n",
    "    points1 /= s1\n",
    "    points2 /= s2\n",
    "\n",
    "    U, S, Vt = numpy.linalg.svd(points1.T * points2)\n",
    "\n",
    "    # The R we seek is in fact the transpose of the one given by U * Vt. This\n",
    "    # is because the above formulation assumes the matrix goes on the right\n",
    "    # (with row vectors) where as our solution requires the matrix to be on the\n",
    "    # left (with column vectors).\n",
    "    R = (U * Vt).T\n",
    "\n",
    "    return numpy.vstack([numpy.hstack(((s2 / s1) * R,\n",
    "                                       c2.T - (s2 / s1) * R * c1.T)),\n",
    "                         numpy.matrix([0., 0., 1.])])\n",
    "\n",
    "def read_im_and_landmarks(fname):\n",
    "    im = cv2.imread(fname, cv2.IMREAD_COLOR)\n",
    "    im = cv2.resize(im, (im.shape[1] * SCALE_FACTOR,\n",
    "                         im.shape[0] * SCALE_FACTOR))\n",
    "    s = get_landmarks(im)\n",
    "\n",
    "    return im, s\n",
    "\n",
    "def warp_im(im, M, dshape):\n",
    "    output_im = numpy.zeros(dshape, dtype=im.dtype)\n",
    "    cv2.warpAffine(im,\n",
    "                   M[:2],\n",
    "                   (dshape[1], dshape[0]),\n",
    "                   dst=output_im,\n",
    "                   borderMode=cv2.BORDER_TRANSPARENT,\n",
    "                   flags=cv2.WARP_INVERSE_MAP)\n",
    "    return output_im\n",
    "\n",
    "def correct_colours(im1, im2, landmarks1):\n",
    "    blur_amount = COLOUR_CORRECT_BLUR_FRAC * numpy.linalg.norm(\n",
    "                              numpy.mean(landmarks1[LEFT_EYE_POINTS], axis=0) -\n",
    "                              numpy.mean(landmarks1[RIGHT_EYE_POINTS], axis=0))\n",
    "    blur_amount = int(blur_amount)\n",
    "    if blur_amount % 2 == 0:\n",
    "        blur_amount += 1\n",
    "    im1_blur = cv2.GaussianBlur(im1, (blur_amount, blur_amount), 0)\n",
    "    im2_blur = cv2.GaussianBlur(im2, (blur_amount, blur_amount), 0)\n",
    "\n",
    "    # Avoid divide-by-zero errors.\n",
    "    im2_blur += (128 * (im2_blur <= 1.0)).astype(im2_blur.dtype)\n",
    "\n",
    "    return (im2.astype(numpy.float64) * im1_blur.astype(numpy.float64) /\n",
    "                                                im2_blur.astype(numpy.float64))\n",
    "\n",
    "im1, landmarks1 = read_im_and_landmarks(sys.argv[1])\n",
    "im2, landmarks2 = read_im_and_landmarks(sys.argv[2])\n",
    "\n",
    "M = transformation_from_points(landmarks1[ALIGN_POINTS],\n",
    "                               landmarks2[ALIGN_POINTS])\n",
    "\n",
    "mask = get_face_mask(im2, landmarks2)\n",
    "warped_mask = warp_im(mask, M, im1.shape)\n",
    "combined_mask = numpy.max([get_face_mask(im1, landmarks1), warped_mask],\n",
    "                          axis=0)\n",
    "\n",
    "warped_im2 = warp_im(im2, M, im1.shape)\n",
    "warped_corrected_im2 = correct_colours(im1, warped_im2, landmarks1)\n",
    "\n",
    "output_im = im1 * (1.0 - combined_mask) + warped_corrected_im2 * combined_mask\n",
    "\n",
    "cv2.imwrite('output.jpg', output_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only did Matt create an excellent face blending algorithm, but we could toggle its effect on an image by manipulating the OVERLAY_POINTS vector and COLOUR_CORRECT_BLUR_FRAC value. \n",
    "\n",
    "### Experiments with Image Blending\n",
    "For the first attempt, we blurred the eyes and mouth of smiling images with 3 random people from the neutral dataset. We wanted to see if this was too much blending (if there was such a thing):"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import os, sys, re, random, subprocess\n",
    "from random import randint\n",
    "\n",
    "def randomNeutral():\n",
    "    f = random.choice(os.listdir(\"neutralFaces/\"))\n",
    "    while \"jpg\" not in f:\n",
    "        f = random.choice(os.listdir(\"neutralFaces/\"))\n",
    "    return \"neutralFaces/\" + f    \n",
    "\n",
    "#print(randomNeutral())\n",
    "#n1 = randomNeutral()\n",
    "#n2 = randomNeutral()\n",
    "#n3 = randomNeutral()\n",
    "\n",
    "for i in range(0,3):\n",
    "    for root,dirs,files in os.walk(\"smileFaces/\"):\n",
    "        for file in files:\n",
    "            if \"jp\" in file:\n",
    "                f = os.path.join(root,file)\n",
    "                swapImg = randomNeutral()\n",
    "                print(\" for: \" + f)\n",
    "                sp = subprocess.Popen(['python3', 'mouthswap.py', f,  swapImg], stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "                sp.wait()\n",
    "            print(\"Done with \" + str(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also created another set of transformed images where we only blended the mouth of a smiling image with one random neutral image.\n",
    "\n",
    "We ran the randomized batch test script from earlier and used gradData.py for data collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral:662\n",
      "Smile: 724\n",
      "Smile blend 3 faces: 839\n",
      "Smile blend 1 face: 681\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAENCAYAAAARyyJwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmVkmJwozM8vkRGFmZpmcKMzMLNP/BxsXxyOgeZ/uAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10857d898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "# Neutral FP\n",
    "n = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 3, 1, 0, 1, 6, 18, 16, 11, 22, 20, 28, 29, 13, 79, 92, 43, 84, 105, 83, 100, 125, 139, 148, 88, 175, 156, 138, 182, 176, 189, 149, 195, 194, 194, 197, 195, 199, 198, 198]\n",
    "\n",
    "# Smile FP\n",
    "s = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 3, 4, 2, 5, 3, 2, 24, 16, 16, 8, 19, 18, 18, 33, 33, 65, 99, 44, 107, 96, 108, 140, 121, 154, 155, 120, 182, 188, 125, 168, 185, 192, 166, 198, 193, 196, 199, 196, 199, 198, 199]\n",
    "\n",
    "# Smile FP with blend eyes and mouth from 3 neutral images\n",
    "modS = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 4, 6, 4, 6, 7, 23, 23, 12, 33, 64, 31, 77, 86, 95, 71, 58, 84, 74, 78, 173, 166, 134, 129, 149, 143, 159, 172, 173, 187, 170, 175, 196, 197, 194, 198, 198, 199, 198, 199]\n",
    "\n",
    "# Smile FP with blended mouth from one neutral image\n",
    "modS_1 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 6, 3, 1, 11, 3, 15, 11, 33, 20, 26, 35, 27, 63, 111, 46, 86, 77, 103, 103, 133, 121, 149, 125, 175, 176, 131, 177, 183, 189, 170, 199, 196, 198, 199, 199, 199, 199, 199]\n",
    "\n",
    "d = {'Neutral' : pd.Series(n),'Smile' : pd.Series(s), 'Smile Blend 1 Face' : pd.Series(modS_1), }\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "b = df.plot.bar()\n",
    "b.set_xlim(55,80)\n",
    "b.set_ylim(0,150)\n",
    "b.set_xlabel(\"Tolerance\")\n",
    "b.set_ylabel(\"# of False Positives\")\n",
    "print(\"Neutral:\" + str(np.sum(n[55:80])))\n",
    "print(\"Smile: \" + str(np.sum(s[55:80])))\n",
    "print(\"Smile blend 3 faces: \" + str(np.sum(modS[55:80])))\n",
    "print(\"Smile blend 1 face: \" + str(np.sum(modS_1[55:80])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the batch testing we see that the smile with 1 face blend did exceptionally better than that standard smile enrollment. When adding up the false positives in the tolerance range 0.55 - 0.8, the blended enrollment image was less than 20 errors away from neutral. That's less than a 3% difference! The regular smile enrollment had 62 more errors, almost a 10% difference from neutral. The 3 blend face actually did worse than 1 blend or the original smile image, so we decided not to go in that direction any further.\n",
    "\n",
    "Next, we repeated this experiment on the Jaffe Dataset:\n",
    "\n",
    "https://github.com/shreyasrao/public/tree/master/unifyIdProject/jaffeDataSet/smile\n",
    "https://github.com/shreyasrao/public/tree/master/unifyIdProject/jaffeDataSet/neutral\n",
    "\n",
    "Earl's swapping script was not able to swap features in the Jaffe dataset. The pictures were all low quality black and white pictures. We still ran our analysis using unmodified images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral FP:334\n",
      "Smile FP: 372\n"
     ]
    }
   ],
   "source": [
    "# Neutral FP from Jaffe DataSet\n",
    "n = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 5, 3, 7, 6, 12, 9, 6, 16, 17, 9, 12, 13, 20, 17, 24, 24, 24, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27]\n",
    "\n",
    "# Smile FP from Jaffe DataSet\n",
    "s = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 5, 6, 2, 9, 1, 14, 14, 6, 18, 20, 12, 23, 16, 25, 15, 25, 25, 25, 28, 28, 28, 26, 26, 28, 27, 28, 28, 28, 29, 28, 28, 27, 29, 28, 28, 28, 29, 28, 28, 28, 28, 27, 28, 29, 28, 27, 28, 28, 28, 28, 28, 28, 28, 27, 28, 28, 28, 28, 28, 28, 28, 28]\n",
    "\n",
    "print(\"Neutral FP:\" + str(np.sum(n[30:60])))\n",
    "print(\"Smile FP: \" + str(np.sum(s[30:60])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw that in a tolerance range of 0.30-0.60, there were substantially more false positives in the smiling image subset. This confirmed the earlier observation from the FM dataset. Next we analyzed the ATT dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral FP:952\n",
      "Smile FP: 925\n"
     ]
    }
   ],
   "source": [
    "# Neutral FP from ATT DataSet\n",
    "n = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 2, 2, 4, 4, 9, 10, 9, 1, 12, 16, 13, 14, 15, 25, 14, 28, 30, 26, 34, 34, 36, 22, 31, 37, 38, 37, 35, 36, 38, 35, 38, 38, 38, 37, 38, 38, 38, 38]\n",
    "\n",
    "# Smile FP from ATT DataSet\n",
    "s = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 2, 1, 2, 0, 3, 5, 10, 4, 6, 1, 13, 9, 8, 5, 20, 23, 15, 27, 29, 15, 34, 34, 36, 14, 37, 35, 36, 37, 38, 38, 39, 35, 39, 39, 39, 39, 39, 39, 39, 39]\n",
    "print(\"Neutral FP:\" + str(np.sum(n)))\n",
    "print(\"Smile FP: \" + str(np.sum(s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shockingly, even though these pictures were also grayscale and lower resolution than the FM dataset, there were less false positives in the smile pictures. Changing the grabData.py parameters showed there were no false negatives in either neutral or smile subset, indicating that face recognition was somehow more accurate on these pictures.\n",
    "\n",
    "Even though it appeared as if using a gray scale low resolution picture for the enrollment image could help solve our spoofing problem, we didn't want make any conclusions just yet. People in the smile subset of the Att dataset were not smiling as wide as the people in the FM dataset. That could have had a big effect on the results. To check for this, we went back and changed all the FM images into lower resolution grayscale and ran the tests once again. \n",
    "\n",
    "Used this code to covert images to grayscale using cv2:\n",
    "https://extr3metech.wordpress.com/2012/09/23/convert-photo-to-grayscale-with-python-opencv/\n",
    "\n",
    "For downsizing images, cv.INTER_AREA is the best interpolation algorithm, according to this analysis:\n",
    "http://tanbakuchi.com/posts/comparison-of-openv-interpolation-algorithms/\n",
    "\n",
    "We downsized the width to 92 pixels (same as ATT dataset) and scaled height accordingly to keep aspect ratio the same:\n",
    "http://www.pyimagesearch.com/2014/01/20/basic-image-manipulations-in-python-and-opencv-resizing-scaling-rotating-and-cropping/"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Convert color images to grayscale\n",
    "import cv2\n",
    "import os, sys, re\n",
    "\n",
    "for root, dirs, files in os.walk(\".\"):\n",
    "    for file in files:\n",
    "        if \"jpg\" not in file:\n",
    "            continue\n",
    "        image = cv2.imread(file)\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imwrite(file,gray_image)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Downsize image\n",
    "import cv2\n",
    "import os, sys, re\n",
    "\n",
    "for root, dirs, files in os.walk(\".\"):\n",
    "    for file in files:\n",
    "        if \"jpg\" not in file:\n",
    "            continue\n",
    "        image = cv2.imread(file)\n",
    "        \n",
    "        # we need to keep in mind aspect ratio so the image does\n",
    "        # not look skewed or distorted -- therefore, we calculate\n",
    "        # the ratio of the new image to the old image\n",
    "        r = 92.0 / image.shape[1]\n",
    "        dim = (92, int(image.shape[0] * r))\n",
    "\n",
    "        # perform the actual resizing of the image and store it\n",
    "        resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "        cv2.imwrite(file,resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral FP:710\n",
      "Smile FP:709\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAENCAYAAAARyyJwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109050a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "zeros = [0] * 50\n",
    "\n",
    "# Gray low res neutral FP from FM dataset\n",
    "nGray = zeros + [0, 0, 0, 0, 0, 0, 0, 0, 1, 5, 8, 10, 0, 3, 4, 13, 21, 11, 13, 21, 20, 29, 29, 17, 67, 113, 41, 82, 124, 78, 102, 122, 147, 154, 116, 177, 164, 131, 185, 170, 190, 156, 193, 194, 197, 197, 195, 199, 198, 198]\n",
    "\n",
    "# Gray low res smile FP from FM dataset\n",
    "sGray = zeros + [0, 0, 0, 0, 1, 0, 1, 0, 0, 3, 3, 7, 1, 0, 5, 20, 18, 11, 10, 29, 22, 23, 30, 27, 55, 101, 44, 104, 102, 93, 127, 129, 152, 151, 146, 180, 186, 136, 182, 185, 193, 177, 198, 193, 199, 199, 197, 199, 199, 199]\n",
    "\n",
    "d = {'Gray Low Res Neutral' : pd.Series(nGray),'Gray Low Res Smile' : pd.Series(sGray)}\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "b = df.plot.bar()\n",
    "b.set_xlim(55,80)\n",
    "b.set_xlabel(\"Tolerance\")\n",
    "b.set_ylabel(\"# of False Positives\")\n",
    "print(\"Neutral FP:\" + str(np.sum(nGray[55:80])))\n",
    "print(\"Smile FP:\" + str(np.sum(sGray[55:80])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further analysis showed that observations from the ATT Dataset were in fact accurate. Low resolution gray scale images had a noticeably less number of false positives. Just as another sanity check, I combined the neutral and smile subsets, and ran another batch test with random smile enrollment images. I wanted to see if there was an increase on false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FN in combined smile and neutral grayscale low res images, tolerance range .55-.8\n",
    "FN = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we had made the images slightly more distored by make them low res, face_recognition was robust enough to pick out both pictures of the same subject (smile and neutral) at every tolerance value in the range 0.55-0.8.\n",
    "\n",
    "## Conclusion\n",
    "In this notebook, we attempted to investigate the notion that a smiling enrollment image leads to more spoofing. Initial testing did show that there was a substantial increase in false positives from smiling enrollment images. The rest of our experiments were to answer the question whether users should be prevented from using smiling enrollment image (either via a warning or filter to detect smiling).\n",
    "\n",
    "To answer that question, we wanted to see whether we could modify an image (smiling or neutral) into a transformed enrollment image that would be used for comparisons. That way, a user could choose any enrollment image and still get a secure means of authentication.\n",
    "\n",
    "We were able to use image blending techniques and show that by swapping a smiling mouth with a neutral mouth, the number of false positives were very similar for neutral and blended images (less than a 3% difference). There was a huge difference between neutral and smiling images (about 10%).\n",
    "\n",
    "While doing further data collection to confirm our observations on the ATT dataset, we saw that lower resolution grayscale images did not show a higher number of false positives in the smiling image subset. We went back to the FM dataset and converted the original images into lower resolution grayscale images. When we ran the batch test again, we confirmed the same trend in the FM dataset that we saw in the ATT dataset.\n",
    "\n",
    "When we downsample and convert the image to grayscale, the number of successful spoofing attempts is the same between neutral and smiling images (in the tolerance range of 0.55-0.8). In tolerance levels below 0.55, there was no spoofing, since the facial recognition system was very robust. At tolerance levels above 0.8, we observed random behavior and did not account for that in the analysis because at that high of a tolerance level, we do not get any type of robust facial recognition, smiling or not. \n",
    "\n",
    "Based on the observations, we can confidently state that there is no need to prompt a user to have a neutral enrollment image in order to prevent spoofing. As long as we downsample the image and convert it to grayscale behind the scenes before using it as the reference image, a user is free to pick the enrollment image of their choice!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
